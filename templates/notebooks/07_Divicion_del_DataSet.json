[
  {
    "type": "markdown",
    "content": "# Divicion de DataSet\nEn este Notebook se muestran algunos de los mecanismos mas utilizados para la divicion del DataSet\n\n## DataSet \n\n### Descripccion \n\nISCX NSL-KDD dataset 2009 \nWe apologize, this dataset is no longer available.\n\nISCX NSL-KDD is a data set suggested to solve some of the inherent problems of the KDD'99 data set which are mentioned in [1]. Although, this new version of the KDD data set still suffers from some of the problems discussed by McHugh and may not be a perfect representative of existing real networks, because of the lack of public data sets for network-based IDSs, we believe it still can be applied as an effective benchmark data set to help researchers compare different intrusion detection methods.\n\nFurthermore, the number of records in the NSL-KDD train and test sets are reasonable. This advantage makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research work will be consistent and comparable.\n\n### Data files\n\n* <spam style=\"color:green\"> KDDTrain+.ARFF: The full NSL-KDD train set with binary labels in ARFF formatm<spam>\n* KDDTrain+.TXT: The full NSL-KDD train set including attack-type labels and difficulty level in CSV format\n* KDDTrain+_20Percent.ARFF: A 20% subset of the KDDTrain+.arff file\n* KDDTrain+_20Percent.TXT: A 20% subset of the KDDTrain+.txt file\n* KDDTest+.ARFF: The full NSL-KDD test set with binary labels in ARFF format\n* KDDTest+.TXT: The full NSL-KDD test set including attack-type labels and difficulty level in CSV format\n* KDDTest-21.ARFF: A subset of the KDDTest+.arff file which does not include records with difficulty level of 21 out of 21\n* KDDTest-21.TXT: A subset of the KDDTest+.txt file which does not include records with difficulty level of 21 out of 21\n* Improvements to the KDD'99 dataset\nThe ISCX NSL-KDD data set has the following advantages over the original KDD data set:\n\nIt does not include redundant records in the train set, so the classifiers will not be biased towards more frequent records.\nThere is no duplicate records in the proposed test sets; therefore, the performance of the learners are not biased by the methods which have better detection rates on the frequent records.\nThe number of selected records from each difficultylevel group is inversely proportional to the percentage of records in the original KDD data set. As a result, the classification rates of distinct machine learning methods vary in a wider range, which makes it more efficient to have an accurate evaluation of different learning techniques.\nThe number of records in the train and test sets are reasonable, which makes it affordable to run the experiments on the complete set without the need to randomly select a small portion. Consequently, evaluation results of different research works will be consistent and comparable.\nStatistical observations\nOne of the most important deficiencies in the KDD data set is the huge number of redundant records, which causes the learning algorithms to be biased towards the frequent records, and thus prevent them from learning unfrequent records which are usually more harmful to networks such as U2R and R2L attacks. In addition, the existence of these repeated records in the test set will cause the evaluation results to be biased by the methods which have better detection rates on the frequent records.\n\nIn addition, we analyzed the difficulty level of the records in KDD data set. Surprisingly, about 98% of the records in the train set and 86% of the records in the test set were correctly classified with all the 21 learners.\n\nIn order to perform our experiments, we randomly created three smaller subsets of the KDD train set each of which included fifty thousand records of information. Each of the learners where trained over the created train sets. We then employed the 21 learned machines (7 learners, each trained 3 times) to label the records of the entire KDD train and test sets, which provides us with 21 predicated labels for each record. Further, we annotated each record of the data set with a #successfulPrediction value, which was initialized to zero. Now, since the KDD data set provides the correct label for each record, we compared the predicated label of each record given by a specific learner with the actual label, where we incremented #successfulPrediction by one if a match was found. Through this process, we calculated the number of learners that were able to correctly label that given record. The highest value for #successfulPrediction is 21, which conveys the fact that all learners were able to correctly predict the label of that record.\n\nStatistics of redundant records in the KDD train set\nOriginal records | Distinct records | Reduction rate\n\nAttacks: 3,925,650 | 262,178 | 93.32%\nNormal: 972,781 | 812,814 | 16.44%\nTotal: 4,898,431 | 1,074,992 | 78.05%\nStatistics of redundant records in the KDD test set\nOriginal records | Distinct records | Reduction rate\n\nAttacks: 250,436 | 29,378 | 88.26%\nNormal: 60,591 | 47,911 | 20.92%\nTotal: 311,027 | 77,289 | 75.15%\n\nLicense\nYou may redistribute, republish, and mirror the ISCX NSL-KDD dataset in any form. However, any use or redistribution of the data must include a citation to the NSL-KDD dataset and the paper referenced below.\n\nReferences: [1] M. Tavallaee, E. Bagheri, W. Lu, and A. Ghorbani, “A Detailed Analysis of the KDD CUP 99 Data Set,” Submitted to Second IEEE Symposium on Computational Intelligence for Security and Defense Applications (CISDA), 2009.\n\n[URL](https://www.unb.ca/cic/datasets/nsl.html)"
  },
  {
    "type": "markdown",
    "content": "## 1.- Lectura del DataSet"
  },
  {
    "type": "text",
    "content": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 125973 entries, 0 to 125972\nData columns (total 42 columns):\n #   Column                       Non-Null Count   Dtype  \n---  ------                       --------------   -----  \n 0   duration                     125973 non-null  float64\n 1   protocol_type                125973 non-null  object \n 2   service                      125973 non-null  object \n 3   flag                         125973 non-null  object \n 4   src_bytes                    125973 non-null  float64\n 5   dst_bytes                    125973 non-null  float64\n 6   land                         125973 non-null  object \n 7   wrong_fragment               125973 non-null  float64\n 8   urgent                       125973 non-null  float64\n 9   hot                          125973 non-null  float64\n 10  num_failed_logins            125973 non-null  float64\n 11  logged_in                    125973 non-null  object \n 12  num_compromised              125973 non-null  float64\n 13  root_shell                   125973 non-null  float64\n 14  su_attempted                 125973 non-null  float64\n 15  num_root                     125973 non-null  float64\n 16  num_file_creations           125973 non-null  float64\n 17  num_shells                   125973 non-null  float64\n 18  num_access_files             125973 non-null  float64\n 19  num_outbound_cmds            125973 non-null  float64\n 20  is_host_login                125973 non-null  object \n 21  is_guest_login               125973 non-null  object \n 22  count                        125973 non-null  float64\n 23  srv_count                    125973 non-null  float64\n 24  serror_rate                  125973 non-null  float64\n 25  srv_serror_rate              125973 non-null  float64\n 26  rerror_rate                  125973 non-null  float64\n 27  srv_rerror_rate              125973 non-null  float64\n 28  same_srv_rate                125973 non-null  float64\n 29  diff_srv_rate                125973 non-null  float64\n 30  srv_diff_host_rate           125973 non-null  float64\n 31  dst_host_count               125973 non-null  float64\n 32  dst_host_srv_count           125973 non-null  float64\n 33  dst_host_same_srv_rate       125973 non-null  float64\n 34  dst_host_diff_srv_rate       125973 non-null  float64\n 35  dst_host_same_src_port_rate  125973 non-null  float64\n 36  dst_host_srv_diff_host_rate  125973 non-null  float64\n 37  dst_host_serror_rate         125973 non-null  float64\n 38  dst_host_srv_serror_rate     125973 non-null  float64\n 39  dst_host_rerror_rate         125973 non-null  float64\n 40  dst_host_srv_rerror_rate     125973 non-null  float64\n 41  class                        125973 non-null  object \ndtypes: float64(34), object(8)\nmemory usage: 40.4+ MB\n"
  },
  {
    "type": "markdown",
    "content": "## 2.- Divicion de DataSet\n\nSe debe de separar el DatSet en los diferentes sudconjuntos necesarios para realizar los procesos de entrenamiento , validacion y pruebas. Sklearn implementan la funcion **train_test_slpit**.\n"
  },
  {
    "type": "text",
    "content": "<class 'pandas.core.frame.DataFrame'>\nIndex: 75583 entries, 98320 to 121958\nData columns (total 42 columns):\n #   Column                       Non-Null Count  Dtype  \n---  ------                       --------------  -----  \n 0   duration                     75583 non-null  float64\n 1   protocol_type                75583 non-null  object \n 2   service                      75583 non-null  object \n 3   flag                         75583 non-null  object \n 4   src_bytes                    75583 non-null  float64\n 5   dst_bytes                    75583 non-null  float64\n 6   land                         75583 non-null  object \n 7   wrong_fragment               75583 non-null  float64\n 8   urgent                       75583 non-null  float64\n 9   hot                          75583 non-null  float64\n 10  num_failed_logins            75583 non-null  float64\n 11  logged_in                    75583 non-null  object \n 12  num_compromised              75583 non-null  float64\n 13  root_shell                   75583 non-null  float64\n 14  su_attempted                 75583 non-null  float64\n 15  num_root                     75583 non-null  float64\n 16  num_file_creations           75583 non-null  float64\n 17  num_shells                   75583 non-null  float64\n 18  num_access_files             75583 non-null  float64\n 19  num_outbound_cmds            75583 non-null  float64\n 20  is_host_login                75583 non-null  object \n 21  is_guest_login               75583 non-null  object \n 22  count                        75583 non-null  float64\n 23  srv_count                    75583 non-null  float64\n 24  serror_rate                  75583 non-null  float64\n 25  srv_serror_rate              75583 non-null  float64\n 26  rerror_rate                  75583 non-null  float64\n 27  srv_rerror_rate              75583 non-null  float64\n 28  same_srv_rate                75583 non-null  float64\n 29  diff_srv_rate                75583 non-null  float64\n 30  srv_diff_host_rate           75583 non-null  float64\n 31  dst_host_count               75583 non-null  float64\n 32  dst_host_srv_count           75583 non-null  float64\n 33  dst_host_same_srv_rate       75583 non-null  float64\n 34  dst_host_diff_srv_rate       75583 non-null  float64\n 35  dst_host_same_src_port_rate  75583 non-null  float64\n 36  dst_host_srv_diff_host_rate  75583 non-null  float64\n 37  dst_host_serror_rate         75583 non-null  float64\n 38  dst_host_srv_serror_rate     75583 non-null  float64\n 39  dst_host_rerror_rate         75583 non-null  float64\n 40  dst_host_srv_rerror_rate     75583 non-null  float64\n 41  class                        75583 non-null  object \ndtypes: float64(34), object(8)\nmemory usage: 24.8+ MB\n"
  },
  {
    "type": "text",
    "content": "Longuitud del Training Set: 75583\nLonguitud del Validation Set: 25195\nLonguitud del Train Set: 25195\n"
  },
  {
    "type": "markdown",
    "content": "### 3.- Particionado aleatorio y stratified sampling\n\nSklearn implementa la funcion **train_test_split**, sin embargo esta funcion por defecto realiza un particionado del DataSet aleatorio para cada vezz que se ejceute el script.Aun añadienuna semilla fija aleatoria , cada vez que se cargue de nuevo en DataSet se generan nevos sudconjuntos .Esto puede ocacionar que despues e muchos intentos , el algoritmo \"vea\" todo el DataSet.\n\nPara solucionar este problema , sklearn ha introducido el parametro **Shuffle** (barajear) en la funcion **train_test_split**."
  },
  {
    "type": "markdown",
    "content": "Estos metodos para dividir el DataSet estan bien si se tiene un conjunto de datos muy grande , pero si no se tiene , se corre el riesgo de introducir **Samopling Bias** (Muestrado con sesgo).\n\nPara utilizar esto , se utiliza un metodo de sampling que se llama **Stratified Sampling**. La poblacion dividida en sudconjuntos homogeneos llamados **strata**. El objectivo es que no quede ninguna caracteristica del DataSet  sin representacion en ninguno de los conjuntos de datos para una o mas caracteristicas en particular (no puedes dejar nuingun elemnto fuera de entrnamiento , porque despues no va a saber que hacer con el).\n\nSkearn introduce el pparametro **Stratify** en la funcion **train_test_split** par acontrolar este comportamiento"
  },
  {
    "type": "markdown",
    "content": "_This strtofy parameter makes a spolit so that te proportion of values in the sample produced will be tha same as the propotion of values provided to parameter stratify._\n\n_For example, if variable \"y\" is binary categorical variable with value 0 and 1 and there are 25%  of zeros and 75% of ones, stratify = y will make sure that your random split has 25% of 0´s and 75% of 1´s._\n\nhttps://en.wikipedia.org/wiki/Stack_Overflow"
  },
  {
    "type": "markdown",
    "content": "### 4.- Generacion de una funcion de particionado"
  },
  {
    "type": "text",
    "content": "Longuitud del DtataSet:  125973\n"
  },
  {
    "type": "text",
    "content": "Longuitud del Training Set: 75583\nLonguitud del Validation Set: 25195\nLonguitud del Train Set: 25195\n"
  },
  {
    "type": "image",
    "content": "/static/notebooks/07_Divicion_del_DataSet/img_1.png"
  },
  {
    "type": "image",
    "content": "/static/notebooks/07_Divicion_del_DataSet/img_2.png"
  },
  {
    "type": "image",
    "content": "/static/notebooks/07_Divicion_del_DataSet/img_3.png"
  },
  {
    "type": "image",
    "content": "/static/notebooks/07_Divicion_del_DataSet/img_4.png"
  }
]